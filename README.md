# Semantic-segmentation-of-aerial-images-using-Deep-learning
The technique for semantic segmentation of aerial 
imagery is one of the most important works that can be done 
based on Deep Learning using Convolutional Neural Networks
(CNN), encoders, and decoders. Semantic segmentation is then 
performed, dividing the image into several semantically 
meaningful segments and assigning a specific label or class to 
each pixel. However, the existing methods face the challenges 
of dealing with different image resolutions, complex scene 
structures, and different land cover types. Therefore, we need 
to extract features and multiple-scale context information from 
the existing U-net model that can help build a new model 
Multi-scale U-net that can provide multi-resolution pathways, 
allowing the model to capture fine-grained details and higherlevel contextual information at different scales. This model 
improves the ability to find object boundaries and increases 
segmentation accuracy. Various segmentation algorithms 
including region-based, edge-based, and cluster-based methods 
are explored in the context of satellite images. The output for
the proposed model is a segmentation-masked image with the 
same dimensions as the input image. The Dubai dataset 
contains aerial imagery acquired from MBRSC satellites that 
can be used to train and test the model. This model can be 
evaluated using pixel accuracy, F1 score, and Jaccard 
coefficient (IOU) to determine the performance of the model.
